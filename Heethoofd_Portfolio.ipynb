{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "161be32e",
   "metadata": {},
   "source": [
    "<div style=\"background-color:\t#41e5d3; text-align:center; vertical-align: middle; padding:40px 0; margin-top:30px\">\n",
    "<h1 style=\"color:white\">ML - Verhuuraantallen voorspellen - Heethoofd</h1>\n",
    "<b style=\"color:white\">Jasper Duncker, Julia Boschman, Nima Agha Ghafar Hamedani</b>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245130f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# metrics etc\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05481e4a",
   "metadata": {},
   "source": [
    "### Bestanden importeren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed4715b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2011-01-01 00:00:00\n",
       "1        2011-01-01 01:00:00\n",
       "2        2011-01-01 02:00:00\n",
       "3        2011-01-01 03:00:00\n",
       "4        2011-01-01 04:00:00\n",
       "                ...         \n",
       "16632    2012-11-30 19:00:00\n",
       "16633    2012-11-30 20:00:00\n",
       "16634    2012-11-30 21:00:00\n",
       "16635    2012-11-30 22:00:00\n",
       "16636    2012-11-30 23:00:00\n",
       "Name: date_hour, Length: 16637, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "Xtest = test.drop(['date_hour'],axis=1)\n",
    "train[\"date_hour\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d024b",
   "metadata": {},
   "source": [
    "## Opdracht 1: EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc0a140",
   "metadata": {},
   "source": [
    "##### Toon datatypes en basisstatistieken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e49c6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16637 entries, 0 to 16636\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date_hour   16637 non-null  object \n",
      " 1   holiday     16637 non-null  int64  \n",
      " 2   weathersit  16637 non-null  int64  \n",
      " 3   temp        16637 non-null  float64\n",
      " 4   atemp       16637 non-null  float64\n",
      " 5   hum         16637 non-null  float64\n",
      " 6   windspeed   16637 non-null  float64\n",
      " 7   cnt         16637 non-null  int64  \n",
      "dtypes: float64(4), int64(3), object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fff089b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16637.000000</td>\n",
       "      <td>16637.000000</td>\n",
       "      <td>16637.000000</td>\n",
       "      <td>16637.000000</td>\n",
       "      <td>16637.000000</td>\n",
       "      <td>16637.000000</td>\n",
       "      <td>16637.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.028671</td>\n",
       "      <td>1.415580</td>\n",
       "      <td>0.504745</td>\n",
       "      <td>0.482608</td>\n",
       "      <td>0.624756</td>\n",
       "      <td>0.190310</td>\n",
       "      <td>190.477009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.166885</td>\n",
       "      <td>0.637298</td>\n",
       "      <td>0.192369</td>\n",
       "      <td>0.171557</td>\n",
       "      <td>0.193227</td>\n",
       "      <td>0.121915</td>\n",
       "      <td>182.026755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.621200</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>282.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850700</td>\n",
       "      <td>977.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            holiday    weathersit          temp         atemp           hum  \\\n",
       "count  16637.000000  16637.000000  16637.000000  16637.000000  16637.000000   \n",
       "mean       0.028671      1.415580      0.504745      0.482608      0.624756   \n",
       "std        0.166885      0.637298      0.192369      0.171557      0.193227   \n",
       "min        0.000000      1.000000      0.020000      0.000000      0.000000   \n",
       "25%        0.000000      1.000000      0.340000      0.333300      0.470000   \n",
       "50%        0.000000      1.000000      0.520000      0.500000      0.620000   \n",
       "75%        0.000000      2.000000      0.660000      0.621200      0.780000   \n",
       "max        1.000000      4.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          windspeed           cnt  \n",
       "count  16637.000000  16637.000000  \n",
       "mean       0.190310    190.477009  \n",
       "std        0.121915    182.026755  \n",
       "min        0.000000      1.000000  \n",
       "25%        0.104500     41.000000  \n",
       "50%        0.194000    143.000000  \n",
       "75%        0.253700    282.000000  \n",
       "max        0.850700    977.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb75a58",
   "metadata": {},
   "source": [
    "Voor het bestand train hebben we gekeken of het voldoet aan alle voorwaardes om een machine learning model te maken:\n",
    "\n",
    "1. Het is een DataFrame\n",
    "2. Het DataFrame heeft geen missende waardes\n",
    "3. Het DataFrame had één kolom die geen numerieke waardes had en die is wordt omgezet naar een datetime kolom. Deze wordt ook gebruikt om nieuwe (numerieke) kolommen aan te maken.\n",
    "\n",
    "Dus het bestand voldoet aan de voorwaardes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a9b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51dfa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a2336",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe(method='percentiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2817e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cce42b",
   "metadata": {},
   "source": [
    "Net als bij het bestand train hebben wij gekeken naar de inhoud van het test bestand. Omdat wij deze gebruiken om uiteindelijk ons model mee te testen willen wij dit in de zelfde vorm hebben staan als het train bestand. Zo gaan wij ook in dit bestand de date_hour kolom omzetten naar een datetime en de kolom wordt gebruikt om verschillende kolommen met numerieke waardes aan te maken. Verder voldoet het ook aan alle voorwaardes:\n",
    "\n",
    "1. Het is een DataFrame.\n",
    "2. Het DataFrame heeft geen missende waardes.\n",
    "3. Het DataFrame heeft alleen numerieke waardes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bad2afb",
   "metadata": {},
   "source": [
    "##### Voeg tijdserie elementen toe en gebruik passende visualisaties om patronen zichtbaar te maken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train['date_hour'] = pd.to_datetime(train['date_hour'])\n",
    "\n",
    "# Voeg dag, week, maand, jaar\n",
    "train['hour_of_day'] = train['date_hour'].dt.hour #Het uur van de dag (0-23).\n",
    "train['day_of_week'] = train['date_hour'].dt.dayofweek #De dag van de week (maandag is 0, zondag is 6).\n",
    "train['week'] = train['date_hour'].dt.isocalendar().week #De weken\n",
    "train['month'] = train['date_hour'].dt.month\n",
    "train['year'] = train['date_hour'].dt.year\n",
    "train[\"day\"] = train[\"date_hour\"].dt.day\n",
    "\n",
    "#Time series / date functionality — pandas 2.1.1 documentation. (n.d.). https://pandas.pydata.org/docs/user_guide/timeseries.html\n",
    "\n",
    "def get_season(month):\n",
    "    if month in [3, 4, 5]:  \n",
    "        return 1\n",
    "    elif month in [6, 7, 8]:  \n",
    "        return 2\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 3\n",
    "    else: \n",
    "        return 4\n",
    "\n",
    "train['season'] = train['month'].apply(get_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb45156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test['date_hour'] = pd.to_datetime(test['date_hour'])\n",
    "\n",
    "# Voeg dag, week, maand, jaar\n",
    "test['hour_of_day'] = test['date_hour'].dt.hour #Het uur van de dag (0-23).\n",
    "test['day_of_week'] = test['date_hour'].dt.dayofweek #De dag van de week (maandag is 0, zondag is 6).\n",
    "test['week'] = test['date_hour'].dt.isocalendar().week #De weken\n",
    "test['month'] = test['date_hour'].dt.month\n",
    "test['year'] = test['date_hour'].dt.year\n",
    "\n",
    "#Time series / date functionality — pandas 2.1.1 documentation. (n.d.). https://pandas.pydata.org/docs/user_guide/timeseries.html\n",
    "\n",
    "def get_season(month):\n",
    "    if month in [3, 4, 5]:  \n",
    "        return 1\n",
    "    elif month in [6, 7, 8]:  \n",
    "        return 2\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 3\n",
    "    else: \n",
    "        return 4\n",
    "\n",
    "test['season'] = test['month'].apply(get_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a8b067",
   "metadata": {},
   "source": [
    "##### Visualisatie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455beead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Invloed van vakantie op het gemiddelde aantal\n",
    "holiday_data = train[train['holiday'] == 1]\n",
    "non_holiday_data = train[train['holiday'] == 0]\n",
    "holiday_avg = holiday_data['cnt'].mean()\n",
    "non_holiday_avg = non_holiday_data['cnt'].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.bar(['Feestdag', 'Geen Feestdag'], [holiday_avg, non_holiday_avg])\n",
    "plt.xlabel('Periode')\n",
    "plt.ylabel('Gemiddeld aantal')\n",
    "plt.title('Invloed van vakantie op het gemiddelde aantal')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b10db6",
   "metadata": {},
   "source": [
    "### Bevindingen feestdagen\n",
    "\n",
    "We zien hier dat er gemiddeld minder van het product gebruikt wordt bij een feestdagen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3803be5",
   "metadata": {},
   "source": [
    "##### Visualisatie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39497f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweede grafiek: Invloed van het uur van de dag op verkoopcijfers\n",
    "hourly_avg = train.groupby('hour_of_day')['cnt'].mean()\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.subplot(122)\n",
    "plt.plot(hourly_avg.index, hourly_avg.values, marker='o')\n",
    "plt.xlabel('Uur van de dag')\n",
    "plt.ylabel('Gemiddeld aantal verkochte producten')\n",
    "plt.title('Invloed van het uur van de dag op verkoopcijfers')\n",
    "plt.xticks(range(24))\n",
    "plt.grid(True)\n",
    "\n",
    "# Invloed van de dag van de week op de verkoop\n",
    "\n",
    "day_of_week_avg = train.groupby('day_of_week')['cnt'].mean()\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(122)\n",
    "plt.bar(day_of_week_avg.index, day_of_week_avg.values)\n",
    "plt.xlabel('Dag van de week')\n",
    "plt.ylabel('Gemiddeld aantal verkochte producten')\n",
    "plt.title('Invloed van de dag van de week')\n",
    "\n",
    "# Invloed van de week op de verkoop\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "weekday_avg = train.groupby('week')['cnt'].mean()\n",
    "plt.subplot(122)\n",
    "plt.bar(weekday_avg.index, weekday_avg.values)\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Gemiddeld aantal verkochte producten')\n",
    "plt.title('Invloed van de weekdag')\n",
    "\n",
    "# Invloed van de maand op de verkoop\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "month_avg = train.groupby('month')['cnt'].mean()\n",
    "plt.subplot(122)\n",
    "plt.bar(month_avg.index, month_avg.values)\n",
    "plt.xlabel('Maand')\n",
    "plt.ylabel('Gemiddeld aantal verkochte producten')\n",
    "plt.title('Invloed van de maand')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ad056f",
   "metadata": {},
   "source": [
    "### Conclusie uur, dag, week, maand\n",
    "\n",
    "#### Conclusie uur\n",
    "\n",
    "Wij zien in deze plot dat er 2 pieken vallen. Dat is om 8 uur en om 17 uur. Deze uren vallen ook in de spitsuren. Door deze bevinding kan het product een relatie hebben met vervoer. (DPG Media Privacy Gate, n.d.)\n",
    "\n",
    "DPG Media Privacy Gate. (n.d.). https://myprivacy.dpgmedia.nl/consent?siteKey=ujm6mv0jrqiz5syr&callbackUrl=https%3A%2F%2Fwww.autoweek.nl%2Fprivacygate-confirm%3FredirectUri%3D%252Fverkeer%252Fzo-vermijd-je-files-en-druk-verkeer-tijdens-de-spits%252F%253Freferrer%253Dhttps%25253A%25252F%25252Fwww.google.com%25252F\n",
    "\n",
    "#### Conclusie dag\n",
    "\n",
    "Wij zien dat er op zaterdag (5) en zondag (6) een kleine daling is tussen het gemiddeld gebruik van het product. Hiebij kan je concluderen dat het product te maken heeft met de werkdagen/schooldagen.\n",
    "\n",
    "#### Conclusie week\n",
    "\n",
    "We zien dat het bij het einde van de officiële zomervakantie er veel gebruikt van het product gebruikt wordt\n",
    "\n",
    "#### Conclusie maand\n",
    "We zien hierbij in de 'warmere maanden'Dat het product vaker gebruikt wordt. Hierdoor kunnen we zeggen dat het een product is dat vaak buiten gebruikt wordt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b57b0",
   "metadata": {},
   "source": [
    "##### Onderzoek de relatie tussen de onafhankelijke en de afhankelijke variabelen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da24e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(121)  \n",
    "heatmap1 = sns.heatmap(train.corr(method='pearson')[['cnt']].sort_values(by='cnt', ascending=False),\n",
    "                       vmin=-1, vmax=1, annot=True, cmap='RdYlGn')\n",
    "heatmap1.set_title('Correlatie cnt', fontdict={'fontsize': 12}, pad=12)\n",
    "\n",
    "\n",
    "plt.subplot(122) \n",
    "heatmap2 = sns.heatmap(train.corr(method='pearson'), vmin=-1, vmax=1, annot=True, cmap='RdYlGn')\n",
    "heatmap2.set_title('Correlatie tussen alle kolommen in train', fontdict={'fontsize': 12}, pad=12)\n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "temp_avg = train.groupby('temp')['cnt'].mean()\n",
    "plt.subplot(122)\n",
    "plt.scatter(temp_avg.index, temp_avg.values)\n",
    "plt.xlabel('Temperatuur')\n",
    "plt.ylabel('Gemiddeld aantal verkochte producten')\n",
    "plt.title('Invloed van de temperatuur')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdcf05b",
   "metadata": {},
   "source": [
    "### Conclusie temperatuur\n",
    "Uit deze visualisatie zien wij het volgende: Hoe warmer het weer, hoe vaker het product wordt gebruikt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98618b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['datum'] = train['date_hour'].dt.date\n",
    "\n",
    "train2011 = train[train[\"year\"] == 2011]\n",
    "train2012 = train[train[\"year\"] == 2012]\n",
    "\n",
    "plt.hist(train2011[\"cnt\"], alpha = 0.3, color = \"purple\", edgecolor = 'w', label= '2011')\n",
    "plt.hist(train2012[\"cnt\"], alpha = 0.4, edgecolor = 'w', label = '2012')\n",
    "plt.xlabel(\"Count of product\")\n",
    "plt.ylabel(\"Amount of times\")\n",
    "plt.title(\"Count of product in 2011 and 2012\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a56dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train2011[\"datum\"].min(), \",\", train2011[\"datum\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8249cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train2012[\"datum\"].min(), \",\", train2012[\"datum\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train2011[\"cnt\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train2012[\"cnt\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2516654e",
   "metadata": {},
   "source": [
    "Het valt ons op dat de data niet helemaal volledig is. Zo zien wij dat er meer datapunten zijn voor het jaar 2011 dan het jaar 2012. Wanneer wij dit verder onderzoeken zien wij dat de maand december ontbreekt in het jaar 2012. Wel zien wij aan de visualisatie dat de waardes van 2012 wel een stuk hoger liggen. Zo zie je in de visualisatie dat in het jaar 2012 waardes liggen tot 977. In 2011 zijn er meerdere waardes die lager liggen. Zo gaat het maximale punt tot 651. Dit is een verschil van eer dan 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e17bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.barplot('year', \"cnt\",hue='season', data=train, ci=None)\n",
    "plt.legend([\"Spring\", \"Summer\", \"Autumn\", \"Winter\"])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total number of count')\n",
    "plt.title('Number of count per season')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a7f043",
   "metadata": {},
   "source": [
    "### Conclusie per seizoen\n",
    "Wij zien dat er in de lente, zomer en herfst meer mensen hebben besloten op het product te gebruiken dan in de winter. Hieruit kan je de hypothese stellen dat het een product is die je buiten gebruikt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18103422",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.barplot('year', \"cnt\",hue='weathersit', data=train, ci=None)\n",
    "plt.legend(['Clear', 'Foggy', 'Light snow', 'Heavy rain'])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total number of count')\n",
    "plt.title('Number of count per weather situation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84421eca",
   "metadata": {},
   "source": [
    "### Conclusie per weer situatie\n",
    "Wij zien dat hoe aantrekkelijker het weer is om naar buiten te gaan, hoe meer er van het product gebruikt wordt. Hieruit kan je de hypothese stellen dat het een product is die je buiten gebruikt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc82bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab0447",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ae406",
   "metadata": {},
   "source": [
    "### Metric Functie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7337d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(model):\n",
    "    \"\"\"\n",
    "    Traint het opgegeven model met behulp van de meegeleverde trainingsgegevens en evalueert het met de testgegevens.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model : model vergelijkbaar met sklearn\n",
    "        Het model dat getraind en geëvalueerd moet worden.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    RMSE :\n",
    "        Deze functie drukt de RMSE score van het model op de testgegevens af.\n",
    "    \n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred= model.predict(X_test)\n",
    "    MSE = mean_squared_error(y_test, y_pred)\n",
    "    RMSE = MSE**0.5\n",
    "    R2 = r2_score(y_test, y_pred)\n",
    "    MAE = mean_absolute_error(y_test, y_pred)\n",
    "    return print('R2:',R2,\n",
    "                 '\\nMAE:', MAE,\n",
    "                 '\\nMSE:',MSE,\n",
    "                 '\\nRMSE:',RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a62365",
   "metadata": {},
   "source": [
    "### TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a69aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_train = train[[\"date_hour\", \"cnt\"]].set_index(\"date_hour\")\n",
    "\n",
    "moving_average = roll_train.rolling(\n",
    "    window=52,       # 365-day window\n",
    "    center=True,      # puts the average at the center of the window\n",
    "    min_periods=26,  # choose about half the window size\n",
    ").mean()              # compute the mean (could also do median, std, min, max, ...)\n",
    "\n",
    "ax = roll_train.plot(style=\".\", color=\"0.5\")\n",
    "moving_average.plot(\n",
    "    ax=ax, linewidth=3, title=\"Renting product - 365-Day Moving Average\", legend=False,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6726bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['datum'] = train['date_hour'].dt.date\n",
    "\n",
    "nieuw_dataframe = train[['datum', 'cnt']]\n",
    "nieuw_dataframe.set_index('datum', inplace=True)\n",
    "nieuw_dataframe.index = pd.to_datetime(nieuw_dataframe.index)\n",
    "\n",
    "dagelijks_resampled = nieuw_dataframe.resample('D').mean()\n",
    "weekly_resampled = nieuw_dataframe.resample('W').mean()\n",
    "\n",
    "#pandas.DataFrame.resample — pandas 2.1.2 documentation. (n.d.). #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html\n",
    "\n",
    "def calculate_trend(df, window_size):\n",
    "    \"\"\"\n",
    "    Calculates the trend component using a rolling window and moving averages\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): DataFrame with a DateTime index and a single column.\n",
    "        window_size: The length of the rolling window in units of time\n",
    "    \"\"\"\n",
    "    trend = df.rolling(window_size, center=True).mean()\n",
    "    return trend\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "trend_calculated = calculate_trend(dagelijks_resampled, window_size=12)\n",
    "\n",
    "plt.plot(trend_calculated, label=\"Trend calculated\", color=\"red\")\n",
    "\n",
    "plt.title(\"Trendlijn\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b9e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_pattern = weekly_resampled.groupby(weekly_resampled.index.dayofweek)['cnt'].mean()\n",
    "\n",
    "weekly_resampled['seasonal_adjusted'] = weekly_resampled['cnt'] - weekly_resampled.index.dayofweek.map(seasonal_pattern)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "plt.plot(weekly_resampled.index, weekly_resampled['seasonal_adjusted'], label='Seizoensgecorrigeerd')\n",
    "plt.xlabel('Datum')\n",
    "plt.ylabel('Waarden')\n",
    "plt.title('Seizoenscomponent visualisatie')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d48b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.copy()\n",
    "train2 = pd.DataFrame(train2.groupby(\"datum\")[\"cnt\"].sum())\n",
    "train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece34457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def decompose_ts(series, period=None):\n",
    "    decompose = sm.tsa.seasonal_decompose(series, period=period)\n",
    "    trend = decompose.trend\n",
    "    seasonal = decompose.seasonal\n",
    "    resid = decompose.resid\n",
    "    return trend, seasonal, resid\n",
    "\n",
    "trend, seasonal, resid = decompose_ts(train2, period= 24)\n",
    "print(trend, seasonal, resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537bec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ts(df, trend, seasonal, residuals):\n",
    "    \"\"\"\n",
    "    Plots the original time series, trend, seasonal, and residual components.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): DataFrame with a DateTime index and a single column.\n",
    "        trend (pandas.Series): Time series representing the trend component.\n",
    "        seasonal (pandas.Series): Time series representing the seasonal component.\n",
    "        residuals (pandas.Series): Time series representing the residual component.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(10, 8))\n",
    "\n",
    "    # Plot the original time series and trend\n",
    "    axes[0].plot(df.index, df.iloc[:, 0], color='blue', label='Original Time Series')\n",
    "    axes[0].plot(df.index, trend, color='black', linestyle='dashed', label='Trend')\n",
    "    axes[0].set_title('Original Time Series and Trend')\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Plot the seasonal component\n",
    "    axes[1].plot(df.index, seasonal, color='green', label='Seasonal Component')\n",
    "    axes[1].set_title('Seasonal Component')\n",
    "    axes[1].legend()\n",
    "\n",
    "    # Plot the residual component\n",
    "    axes[2].plot(df.index, residuals, color='red', label='Residual Component')\n",
    "    axes[2].set_title('Residual Component')\n",
    "    axes[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_ts(train2, trend, seasonal, resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2b6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(roll_train)\n",
    "\n",
    "# Compute the Fourier transform of the timeseries\n",
    "train_ft = np.fft.fft(roll_train['cnt'])\n",
    "\n",
    "# Compute the magnitude of the frequencies\n",
    "magnitude = 2.0/N * np.abs(train_ft[:N//2])\n",
    "\n",
    "# Plot the constituent frequencies\n",
    "plt.plot(magnitude)\n",
    "plt.xlabel('Frequency (1/N)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title(\"Frequency domain of rentals timeseries\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c037b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "peaks, _ = find_peaks(magnitude, height=45) # Je kunt de \"height\" parameter bewerken om meer of minder pieken te vinden.\n",
    "\n",
    "print(f\"Peaks found at {peaks}\")\n",
    "\n",
    "plt.plot(magnitude)\n",
    "plt.xlabel('Frequency (1/N)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title(\"Frequency domain of mixture\")\n",
    "\n",
    "plt.plot(peaks, magnitude[peaks], \".\", markersize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6e089f",
   "metadata": {},
   "source": [
    "De dominante frequenties zijn 2, 692, 694 en 1387. Wij slaan 2 over, omdat deze heel dicht bij de 0 ligt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba770af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for peak in peaks:\n",
    "    print(N/peak)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aac3825",
   "metadata": {},
   "source": [
    "Het valt ons op dat er een aantal dominante frequenties zijn. Wij hebben deze waardes omgerekend naar uren. Wij zien een duidelijk verband op het niveau van een jaar, een dag en een halve dag. Wij gaan een halve dag niet gebruiken, omdat deze waarde geen toevoeging heeft aan ons specifieke onderzoek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3bca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.set_index('date_hour')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ff679",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index('date_hour')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e435b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
    "\n",
    "fourier1 = CalendarFourier(freq=\"A\", order=1)  # 1 sin/cos pairs for \"A\"nnual seasonality\n",
    "fourier2 = CalendarFourier(freq=\"D\", order=2)  # 1 sin/cos pairs for \"A\"nnual seasonality\n",
    "\n",
    "dp = DeterministicProcess(\n",
    "    index=train.index,\n",
    "    constant=False,               # dummy feature for bias (y-intercept)\n",
    "    order=1,                     # trend (order 1 means linear)\n",
    "    seasonal=False,               # weekly seasonality (indicators)\n",
    "    additional_terms=[fourier1,fourier2],  # annual seasonality (fourier)\n",
    "    drop=True,                   # drop terms to avoid collinearity\n",
    ")\n",
    "\n",
    "X = dp.in_sample()  # create features for dates in tunnel.index\n",
    "X2 = dp.out_of_sample(steps=len(test.index),forecast_index= test.index)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['sin(1,freq=A-DEC)'].plot()\n",
    "X['cos(1,freq=A-DEC)'].plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366aaba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['sin(1,freq=D)'].plot()\n",
    "X['cos(1,freq=D)'].plot()\n",
    "plt.xlim('2011-01-01','2011-01-05')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef145020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "plot_pacf(train[\"temp\"], lags = 40, method = \"ywm\")\n",
    "plt.title(\"PACF\")\n",
    "plt.ylim([-0.25, 0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128c342",
   "metadata": {},
   "source": [
    "Wij zien in de visualisatie hierboven dat het 6e punt in het blauwe gebied valt. Dit wilt zeggen dat wij voor ons onderzoek gebruik gaan maken van 5 lags. Wij gebruiken deze om een goede voorspelling te maken. Zo staan alle punten buiten het blauwe gebied voor de lags die een goede voorspelling kunnen maken. Wij kiezen voor temperatuur, omdat dit een kolom is die volgens ons veel invloed heeft op het verhuren van het product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5f9bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lags(ts, lags, lead_time=1):\n",
    "    return pd.concat(\n",
    "        {\n",
    "            f'y_lag_{i}': ts.shift(i)\n",
    "            for i in range(0, lags + lead_time)\n",
    "        },\n",
    "        axis=1)\n",
    "\n",
    "df_lags = make_lags(train['temp'], lags=5)\n",
    "df_lags = df_lags.fillna(0.0)\n",
    "df_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a3337",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = X.columns.difference(train.columns)\n",
    "cols_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6161d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew = train.merge(X[cols_to_use], left_index=True, right_index=True, how='outer')\n",
    "dfNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d97c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew = pd.get_dummies(data = dfNew, columns=['day_of_week','holiday','hour_of_day'])\n",
    "dfNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = df_lags.columns.difference(dfNew.columns)\n",
    "cols_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c58298",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew = dfNew.merge(df_lags[cols_to_use], left_index=True, right_index=True, how='outer')\n",
    "dfNew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce4f798",
   "metadata": {},
   "source": [
    "### Maken van testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d12b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb1f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2['sin(1,freq=D)'].plot()\n",
    "X2['cos(1,freq=D)'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9602def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lags(ts, lags, lead_time=1):\n",
    "    return pd.concat(\n",
    "        {\n",
    "            f'y_lag_{i}': ts.shift(i)\n",
    "            for i in range(0, lags + lead_time)\n",
    "        },\n",
    "        axis=1)\n",
    "\n",
    "df_lags_test = make_lags(test['temp'], lags=5)\n",
    "df_lags_test = df_lags_test.fillna(0.0)\n",
    "df_lags_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e63636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use_1 = X2.columns.difference(test.columns)\n",
    "df_test = test.merge(X2[cols_to_use_1], left_index=True, right_index=True, how='outer')\n",
    "df_test = pd.get_dummies(data = df_test, columns=['day_of_week','holiday','hour_of_day'])\n",
    "cols_to_use_2 = df_lags_test.columns.difference(df_test.columns)\n",
    "df_test = df_test.merge(df_lags_test[cols_to_use_2], left_index=True, right_index=True, how='outer')\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a077d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use_1 = dfNew.columns.difference(df_test.columns)\n",
    "cols_to_use_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea14a93",
   "metadata": {},
   "source": [
    "### Train, test, split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106fe95e",
   "metadata": {},
   "source": [
    "Voor de time series moet er een andere split worden gebruikt dan de train_test_split. We moeten een split doen door cross validation toe te passen of bijvoorbeeld door X[:200] & X[200:900]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ad55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = dfNew.drop(['cnt','datum', 'day', 'holiday_1'],axis=1)\n",
    "y = dfNew['cnt']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=3*7*24, random_state=27, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a48beb",
   "metadata": {},
   "source": [
    "### LinearReg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43630fef",
   "metadata": {},
   "source": [
    "Lineaire regressie is een statistische methode die wordt gebruikt om de relatie tussen twee variabelen te modelleren, waarbij we proberen te voorspellen hoe de ene variabele verandert als de andere verandert. Het doel is om een rechte lijn te vinden die het beste past bij de gegeven datapunten.\n",
    "\n",
    "Stel je voor dat we de relatie tussen de uren die je besteedt aan studeren (onafhankelijke variabele) en je behaalde cijfer (afhankelijke variabele) willen begrijpen. Lineaire regressie zou proberen een rechte lijn te vinden die het beste past bij de gegeven datapunten, zodat we kunnen voorspellen welk cijfer je zou halen op basis van het aantal uren studie.\n",
    "\n",
    "De wiskundige vergelijking van een lineaire regressie is meestal iets als:\n",
    "\n",
    "\\[ y = mx + b \\]\n",
    "\n",
    "Waarbij:\n",
    "- \\( y \\) is de afhankelijke variabele (bijvoorbeeld je cijfer)\n",
    "- \\( x \\) is de onafhankelijke variabele (bijvoorbeeld het aantal uren studie)\n",
    "- \\( m \\) is de helling van de lijn\n",
    "- \\( b \\) is het snijpunt met de y-as\n",
    "(What Is Linear Regression?- Spiceworks - Spiceworks, 2023)\n",
    "\n",
    "Om de beste lijn te vinden, gebruiken we een \"loss functie\" die de afstand tussen de voorspelde waarden en de werkelijke waarden meet. Het doel is om deze afstand te minimaliseren.\n",
    "Loss functies worden gebruikt om de prestaties van machine learning-modellen te beoordelen door de voorspelde waarden te vergelijken met de werkelijke waarden. Hier zijn enkele veelgebruikte loss functies voor regressiemodellen:\n",
    "\n",
    "\n",
    "- Mean Absolute Error (MAE):\n",
    "Berekent het gemiddelde absolute verschil tussen voorspelde en werkelijke waarden.\n",
    " - Voordeel: Eenvoudig te berekenen.\n",
    " - Nadeel: Niet differentieerbaar bij nul.\n",
    "\n",
    "- Mean Squared Error (MSE):\n",
    "Berekent het gemiddelde gekwadrateerde verschil tussen voorspelde en werkelijke waarden.\n",
    " - Voordeel: Efficiënt voor optimalisatiealgoritmen, geeft meer gewicht aan grote fouten.\n",
    " - Nadeel: Gevoelig voor outliers.\n",
    "\n",
    "\n",
    "- Root Mean Squared Error (RMSE):\n",
    "Wortel van MSE, meet de gemiddelde magnitude van de fouten.\n",
    " - Voordeel: Makkelijk te begrijpen.\n",
    " - Nadeel: Gevoelig voor outliers, afhankelijk van schaal van de data. (Muniraj, 2022)\n",
    "\n",
    "Soms voegen we ook \"regularisatie\" toe aan het model, wat helpt om overmatige complexiteit te voorkomen en overfitting te verminderen. Overfitting treedt op wanneer het model te sterk is aangepast aan de trainingsgegevens en slecht presteert op nieuwe, ongeziene gegevens.\n",
    "\n",
    "- Wat is regulering in lineaire regressie?\n",
    "Regulering voegt een straftoekenning toe aan de lossfunctie van een lineair regressiemodel om de\n",
    "grootte van coëfficiënten of gewichten te verminderen. Er zijn twee soorten regulering: L1 (Lasso) en L2 (Ridge), die coëfficiënten op verschillende manieren beïnvloeden.\n",
    "\n",
    "- Implementatie van Regulering in Lineaire Regressie:\n",
    "Gebruik Lasso (L1) en Ridge (L2) klassen in tools zoals scikit-learn in Python. L1 maakt bepaalde coëfficiënten nul (sparse model), terwijl L2 alle coëfficiënten naar nul schuift (maar niet precies naar nul).\n",
    "\n",
    "- Voordelen en nadelen van regulering in lineaire regressie:\n",
    " - Voordelen: Vermindert overaanpassing, verbetert generalisatie, behandelt multicollineariteit.\n",
    " - Nadelen: Kan onderaanpassing introduceren, nauwkeurigheid verminderen, en vereist zorgvuldige afstemming en validatie. (How Do You Explain the Impact of Regularization on the Bias-variance Trade-off in Linear Regression?, n.d.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8af00e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "# Linear Regression\n",
    "print(\"Linear:\")\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "train_test_model(lin_reg)\n",
    "lin_reg_pred = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff05d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_pred = lin_reg.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87a7577",
   "metadata": {},
   "source": [
    "### Random Forest (Ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f24e7f",
   "metadata": {},
   "source": [
    "Een Random Forest model is een supervised learning algoritme. Dat wilt zeggen dat met model leert van gelabelde input. Je hebt twee vormen van een Random Forest model. Zo heb je een RandomForestClassfier en een RandomForestRegressor. Het verschil tussen de twee:\n",
    " - RandomForestClassfier = voor classificatie data, zoals het voorspellen van diabetes. Hierin is 0 geen diabetes en 1 is wel diabetes.\n",
    " - RandomForestRegressor = voor het voorspellen van een regressie. Zo zijn er een hele hoop (continue) waardes die gebruikt worden. Bijvoorbeeld bij het voorspellen van verhuuraantallen. Ze kijken hier naar een aantal en dat is niet zomaar 0 of 1.\n",
    "    \n",
    "Een Random Forest is een belangrijk model, omdat het een ensamble is. Dat wilt zeggen dat het meerdere modellen gebruikt om te trainen. Bij een Random Forest is dit een iets ander geval. Hier wordt namelijk één model meerdere keren meegenomen tijdens het trainen. Dit model heet een Decision Tree\n",
    "\n",
    "De werking van beide modellen zijn ook wat anders. De werking van beide modellen zijn:\n",
    " - RandomForestClassfier = Er worden meerdere Decision Trees getraind en daarvan wordt de meest voorkomende waarde voorspeld. Er wordt hier dan ook gebruikt gemaakt van een concept genaamd 'voting'. Als wij dit vertalen krijgen wij het woord stemmen. Makkelijker gezegd kijkt een Random Forest Classifier dus naar de 'meeste stemmen gelden'.\n",
    " - RandomForestRegressor = Er worden net als bij de classifier meerdere Decision Trees gebruikt om het model te trainen. Het verschil tussen de twee komt neer op de waardes van de data. Zo kan een regressie model niet werken met stemmen. Omdat alle waardes anders zijn zou hier nooit een waarde uit kunnen komen, omdat alles maar één keer voor komt. Bij een Random Forest Regressor wordt er dus gebruikt gemaakt van het gemiddelde van alle voorspelde punten. \n",
    "- De werking van het Decision Tree model wordt hieronder nog uitgebreid uitgelegd.\n",
    "\n",
    "Ook zijn er een aantal parameters die kunnen worden ingesteld bij het trainen van een Random Forest model:\n",
    "- n_estimators = de hoeveelheid Decision Trees je wilt gebruiken tijdens het trainen. Bij een classfier is het handig om een oneven aantal te gebruiken. Anders zou het voor kunnen komen dat je een gelijkspel krijgt. Bijvoorbeeld met een n_estimators van 4 kan het zijn dat 2 keer het model 0 aangeeft en 2 keer 1. Om dat te voorkomen kan er bij een classifier beter gebruik worden gemaakt van een oneven aantal. Bij een regressie maakt dit niet uit, omdat er gekeken wordt naar het gemiddelde.\n",
    "- min_samples_leaf = de diepte van de \"boom\". Er moet wel goed nagedacht zijn over deze waarde. Zo kan een te kleine waarde leidden tot underfitting en een te hoge waarde juist weer leidden tot overfitting.\n",
    "    \n",
    "Er is wel een nadeel van dit model. Omdat het model tijdens het trainen moet kijken naar meerdere Decision Trees duurt het een stuk langer om output te leveren. Dat komt omdat hij alle Decision Tree modellen af moet gaan voor hij een goede voorspelling kan doen.\n",
    "\n",
    "##### Wiskunde Formule:\n",
    "RF(x) = 1/N ∑ (N, i=1) hi(x)\n",
    "\n",
    "Waarbij\n",
    "\n",
    "- RF = voorspelling van het Random Forest model voor de input van x\n",
    "- N = het aantal bomen in de Forest (het bos)\n",
    "- hi = de voorspelling van de i-ste (beginnend bij 1) boom voor de input van x\n",
    "    \n",
    "Kortom, het gemiddelde van de som van alle Decision Trees.\n",
    "\n",
    "(ChatGPT, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab85e86f",
   "metadata": {},
   "source": [
    "Uit de gridsearch zijn de volgende parameters gekomen:\n",
    "\n",
    "    param grid:\n",
    "    {'estimator': squared_error,\n",
    "     'max_depth': 17,\n",
    "     'min_samples_split' = 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a9fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(random_state = 27, max_depth = 17, min_samples_split = 9)\n",
    "train_test_model(rf_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476dbb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf_reg.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e13b232",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bdafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_reg = GradientBoostingRegressor(random_state=27, n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "train_test_model(gb_reg)\n",
    "rf_pred = gb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pred = gb_reg.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20071543",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be6bd32",
   "metadata": {},
   "source": [
    "Een Decision Tree is een model met een hiërarchie. Zoals de naam al zegt is een Decision Tree net als een boom. Het enige verschil is dat het een omgedraaide boom is in ons model. Zo begin je bij de \"Root\" (stam) en ga je steeds dieper de \"Leafs\" (bladeren) in. Er zijn een aantal belangrijke begrippen binnen een Decision Tree:\n",
    "- Root node = het eerste punt van het model. Hier wordt de eerste splitsing gemaakt. Wordt ook wel gezien als de stam van de boom.\n",
    "- Branches: de lijnen tussen de nodes (punten) die de nodes opsplitsen.\n",
    "- Internal nodes = alle punten die nog een laag verder gaan. Dit worden ook wel gezien als nodes met een child node. Denk aan een familie stam boom. Hier gaat het van de ouders (internal nodes) ook door tot de kinderen (child nodes).\n",
    "- Leaf node = Het diepste punt van de Decision Tree. Opslitsen in kleine subkopjes is niet meer mogelijk. Denk weer aan de boom. Een \"Leaf\" (blaadje) is het uiterste punt van een boom. Daar groeit niks meer aan.\n",
    "\n",
    "Een Decision Tree is opgedeeld in een soort vragen systeem. Het geen een waarde aan van een kolom. Heeft het een waarde die lager is dan de gegeven waarde, dan gaat hij naar de ene node. Is de waarde hoger dan de gegeven waarde, dan gaat hij naar de andere node. Dit gebeurt zo lang tot we zijn aangekomen bij de leaf nodes.\n",
    "\n",
    "Voordelen:\n",
    "- Je kunt nummeriek en niet nummerieke data in combinatie gebruiken.\n",
    "- En Decision Tree kan visueel worden weergegeven wat het makkelijker maakt om het te begrijpen en uit te leggen.\n",
    "\n",
    "Nadelen:\n",
    "- Het kan instabiel zijn, omdat een kleine verandering kan leiden tot een compleet andere uitslag. zo kunnen er verkeerde voorspellingen worden gedaan die niet realistisch zijn in een samenleving.\n",
    "- Bij een te diepe \"boom\" kan er snel sprake zijn van overfitting.\n",
    "- Bij een te ondiepe \"boom\" kan er snel sprake zijn van underfitting.\n",
    "\n",
    "(WallStreetMojo, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87bdd1",
   "metadata": {},
   "source": [
    "Uit de gridsearch zijn de volgende parameters gekomen:\n",
    "\n",
    "    param grid:\n",
    "    {'criterion': friedman_mse,\n",
    "     'max_depth': 18,\n",
    "     'min_samples_split' = 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_reg = DecisionTreeRegressor(criterion= 'friedman_mse', min_samples_split = 8, max_depth = 13, random_state = 27)\n",
    "train_test_model(dt_reg) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6fc65e",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9966e076",
   "metadata": {},
   "source": [
    "Support Vector Regression (SVR) is een vorm van Support Vector Machine (SVM) die wordt gebruikt voor het voorspellen van continue uitvoerwaarden, door middel van patronen in data te vinden en voorspellingen te doen op basis van die patronen. Het aspect van 'ondersteunende vectoren' in SVR duidt op de punten die zich het dichtst bij de regressielijn bevinden en een significante invloed uitoefenen op de positie van die lijn. Het hoofddoel is om de modelfouten binnen een vooraf bepaalde tolerantie te handhaven. (ChatGPT, 2023, prompt 1: SVR Model Explained.)\n",
    "\n",
    "Kernel Types:\n",
    "SVR kan zowel lineaire als niet-lineaire kernels gebruiken.\n",
    " - Lineaire kernel: Eenvoudig inwendig product tussen invoervectoren.\n",
    " - Niet-lineaire kernel (bijvoorbeeld 'RBF' - radiale basisfunctie): Kan complexere patronen in de gegevens vastleggen.\n",
    "\n",
    "In de scikit-learn-bibliotheek voor Python gebruik je de 'SVR'-klasse. \n",
    " - Kernels: SVR gebruikt kernels om gelijkenis tussen invoervectoren te bepalen. Lineaire kernels zijn eenvoudige inwendige producten, terwijl niet-lineaire kernels complexere patronen kunnen vastleggen.\n",
    "    \n",
    " - Hyperparameters: \n",
    "    SVR heeft instellingen zoals de 'C'-parameter die het modelgedrag beïnvloeden. Een hogere 'C'-waarde maakt het model strenger, terwijl een lagere waarde toegeeflijker is.\n",
    "    \n",
    "(GeeksforGeeks, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(colsample_bytree = 0.8, learning_rate = 0.1, max_depth = 7, n_estimators = 200, subsample = 0.5)\n",
    "train_test_model(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0846a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5874b016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbcc04ee",
   "metadata": {},
   "source": [
    "### Hybride model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a6eeb",
   "metadata": {},
   "source": [
    "Zoals de naam al aangeeft is een hybride model een combinatie of kruising tussen twee (of meer) modellen. Het trainen van een hybride model wordt gedaan in een aantal stappen. Zo wordt er eerst een model getraind op de manier dat je gewend bent. In ons voorbeeld trainen wij eerst een Random Forest model. Hiervoor gebruiken wij de zelfde parameters als bij het trainen van ons losse Random Forest model. Hierna trainen wij een Gradient Boosting model. Tijdens het trainen van het Gradient Boosting model wordt er gebruik gemaakt van de uitkomsten van de voorspellingen van het Random Forest model. Ook wordt voor de voorspellingen van het Gradient Boosting model gebruik gemaakt van de voorspellingen met het Random Forest model. \n",
    "\n",
    "Dit model zou betere voorspellingen moeten geven, omdat het model uitgaat van de voorspellingen van twee (of meer) modellen. Een punt wat een Hybride model anders maakt dan andere ensemble modellen is het feit dat een Hybride model alleen modellen kunnen gebruiken die hetzelfde probleem willen voorspellen. \n",
    "\n",
    "In conclussie gebruik je dus meerdere modellen om tot voorspellingen te komen. Het ene model wordt gebruikt om voor het andere model voorspellingen te doen. Dit werkt anders bij andere modellen waar wij bijvoorbeeld zien dat er meerdere modellen worden gebruikt om tot één antwoord te komen. Dit gebeurt dan om het gemiddelde te pakken tijdens de training. Bij een Hybride model wordt er eerst een model getraind en dat model wordt weer gebruikt om de definitieve voorspellingen op te doen. Dit gaat dus in meerdere stappen. (Wikipedia contributors, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037980c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train een Decision Tree-regressor op de trainingsdata\n",
    "random_forest = RandomForestRegressor(random_state = 27, max_depth = 17, min_samples_split = 9)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_predictions = random_forest.predict(X_test)\n",
    "# Gebruik de voorspellingen van de Decision Tree als functies voor een Linear Regression-model\n",
    "gb_reg = GradientBoostingRegressor(random_state=27, n_estimators=100, max_depth=5, learning_rate=0.1)\n",
    "gb_reg.fit(random_predictions.reshape(-1, 1), y_test)\n",
    "# Maak voorspellingen op de testdata met het hybride model\n",
    "hybrid_predictions = gb_reg.predict(random_predictions.reshape(-1, 1))\n",
    "\n",
    "# Evalueer de prestaties van het hybride model\n",
    "rmse = np.sqrt(np.mean((hybrid_predictions - y_test) ** 2))\n",
    "print(f'Hybride model Root Mean Squared Error: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4431fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_predictions = random_forest.predict(df_test)\n",
    "# Use Random Forest predictions as features for Gradient Boosting\n",
    "hybrid_pred = gb_reg.predict(random_forest_predictions.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3596468b",
   "metadata": {},
   "source": [
    "ChatGPT,(2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e043033f",
   "metadata": {},
   "source": [
    "### Pushen Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f51d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_dataframe(p_id_values, predictions_values, push=True, csv_file_path=None):\n",
    "    \"\"\"\n",
    "    Creëert een DataFrame met kolommen 'p_id' en 'predictions' en slaat het op naar een CSV-bestand (optioneel).\n",
    "\n",
    "    Args:\n",
    "        p_id_values (list): Een lijst met waarden voor de 'p_id'-kolom.\n",
    "        predictions_values (list): Een lijst met waarden voor de 'predictions'-kolom.\n",
    "        push (bool): Een boolean die aangeeft of het DataFrame moet worden opgeslagen naar een CSV-bestand.\n",
    "        csv_file_path (str): Het pad naar het CSV-bestand waarin het DataFrame moet worden opgeslagen (alleen nodig als push=True).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Een DataFrame met de opgegeven kolommen.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Flatten the predictions_values array if it's 2D\n",
    "    if len(predictions_values.shape) > 1:\n",
    "        predictions_values = predictions_values.flatten()\n",
    "        \n",
    "    data = {'date_hour': p_id_values, 'cnt': predictions_values}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    if push and csv_file_path:\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "        print(f\"CSV file '{csv_file_path}' has been created.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e85a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = r'C:\\Users\\bosch\\OneDrive - De Haagse Hogeschool\\Bureaublad\\ADS&AI\\Machine Learning\\Modellen Portfolio 2\\gb_pred_1.csv'\n",
    "\n",
    "#parameters\n",
    "id_values = test.index # niet veranderen\n",
    "predictions_values = gb_pred #predictions van model\n",
    "\n",
    "# push functie toepassen\n",
    "push_dataframe(id_values, predictions_values, push=False, csv_file_path=csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661455f9",
   "metadata": {},
   "source": [
    "### Literatuurlijst\n",
    "**Linear Regression:**\n",
    "- What is Linear Regression?- Spiceworks - Spiceworks. (2023, April 3). Spiceworks. https://www.spiceworks.com/tech/artificial-intelligence/articles/what-is-linear-regression/\n",
    "\n",
    "- Muniraj, P. (2022, February 25). Loss functions to evaluate Regression Models - Analytics Vidhya - Medium. Medium. https://medium.com/analytics-vidhya/loss-functions-to-evaluate-regression-models-8dac47e327e2\n",
    "\n",
    "- How do you explain the impact of regularization on the bias-variance trade-off in linear regression? (n.d.). https://www.linkedin.com/advice/0/how-do-you-explain-impact-regularization-bias-variance\n",
    "\n",
    "**Random Forest:**\n",
    "- ChatGPT, 2023, Random Forest Regressor Formula. https://chat.openai.com/share/97f92d1a-0bbb-4aef-9269-be6fd4be7234\n",
    "\n",
    "- AMO. (2022, 4 februari). Het principe van de werking van Random Forest | AMO-PB Icastat. AMO-PB Icastat | advies- en ingenieursbureau modellering, optimalisatie en statistiek. https://www.amo-nl.com/het-principe-van-de-werking-van-random-forest/\n",
    "\n",
    "**GradientBoosting:**\n",
    "\n",
    "**Decision Tree:**\n",
    "- WallStreetMojo, 2023. Decision Tree. https://www.wallstreetmojo.com/decision-tree/\n",
    "\n",
    "**SVR:**\n",
    "-  GeeksforGeeks. (2023, January 30). Support Vector Regression  SVR  using Linear and Non Linear Kernels in Scikit Learn. https://www.geeksforgeeks.org/support-vector-regression-svr-using-linear-and-non-linear-kernels-in-scikit-learn/\n",
    "\n",
    "- ChatGPT, 2023, prompt 1: SVR Model Explained. https://chat.openai.com/share/db240b56-5072-420e-a99c-174cf7d7640a\n",
    "\n",
    "\n",
    "**Hybride Model:**\n",
    "- Wikipedia contributors. (2023, 3 februari). Hybrid algorithm. Wikipedia. https://en.wikipedia.org/wiki/Hybrid_algorithm\n",
    "- ChatGPT, 2023, Hybride Model met TensorFlow. https://chat.openai.com/c/b66a0bdf-da6d-4141-8177-ed8c6ee7ad66"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
